\section{Introduction}
Implementing a dynamic language such as Python with a compiler rather than with an interpreter improves performances at the cost of
an increasing complexity. Furthermore, generating code for high level virtual machines like CLI or JVM enhances portability and inter-operability.

Writing a compiler that targets the CLI or JVM is easier than targeting a real CPU, but
it still requires a lot of work, as IronPython\footnote{\texttt{http://www.codeplex.com/IronPython}},
Jython\footnote{\texttt{http://www.jython.org/}} and JRuby\footnote{\texttt{http://jruby.codehaus.org/}} demonstrate.
Finally, if one really seeks for an efficent language implementation, \emph{Just In Time} (JIT) compilation needs
to be considered; only in this way  the compiler can exploit runtime type
information to generate quite efficient code. Note that JIT compilation
has not to be confused with lazy compilation of IronPython and Jython which is exploited to save memory, 
since in these cases no runtime type information is ever used to generate more efficient code.

Unfortunately, writing a JIT compiler is a very complex task.  
To make this task simpler, the solution proposed by PyPy \cite{RiBo07_223}  
is automatic generation of JIT compilers with the help of partial evaluation techniques: 
the user has only to provide an interpreter manually annotated with \emph{hints}
specifying how interpretation and JIT compilation has to be interleaved \cite{PyPyJIT09}.

More precisely, in this paper we focus on the ability of generating a JIT compiler able to emit code
for the .NET virtual machine. To our knowledge, this is the first experiment with an interpreter with
two \emph{layers} of JIT compilation, since, before being executed, the
emitted code is eventually compiled again by .NET's own JIT compiler.

The main contribution of this paper is to demonstrate that the idea of
\emph{JIT layering} can give good results, as dynamic languages can be even
faster than their static counterparts.

\subsection{Overview of PyPy}

The \emph{PyPy} project\footnote{\texttt{http://codespeak.net/pypy/}}
\cite{RigoPedroni06} was initially conceived to develop an implementation of Python which
could be easily portable and extensible without renouncing efficiency.
To achieve these aims, the PyPy implementation is based on a highly
modular design which allows high-level aspects
to be separated from lower-level implementation details.
The abstract semantics of Python is defined by an interpreter written
in a high-level language, called RPython \cite{AACM-DLS07}, which is in fact a subset of
Python where some dynamic features have been sacrificed to allow an
efficient translation of the interpreter to low-level code\footnote{But note that it's a full Python interpreter; RPython is only the
language in which this interpreter is written.}.

Compilation of the interpreter is implemented as a stepwise
refinement by means of a translation toolchain which performs type
analysis, code optimizations and several transformations aiming at 
incrementally providing implementation details such as memory management or the threading model.
The different kinds of intermediate codes  which are refined 
during the translation process are all represented by a collection of control flow graphs,
at several levels of abstractions.

Finally, the low-level control flow graphs produced by the toolchain
can be translated to executable code for a specific platform by a
corresponding backend.
Currently, three fully developed backends are available to produce
executable C/POSIX code, Java and CLI/.NET bytecode. 

Despite having been specifically developed for Python, the PyPy infrastructure
can in fact be used for implementing other languages. Indeed, there were
successful experiments of using PyPy to implement several other languages such
as Smalltalk \cite{BolzEtAl08}, JavaScript, Scheme and Prolog.

\commentout{
As suggested by Figure~\ref{pypy-fig}, a portable interpreter for a
generic language $L$  can be
easily developed once an interpreter for $L$ has been implemented in
RPython.
}

\subsection{PyPy and JIT-Generation}
\label{sec:jitgen}

One of the most important aspects that PyPy's translation toolchain can weave
in is the \emph{automatic generation of a JIT compiler}.  This section will
give a high-level overview of how the JIT-generation process works. More
details can be found in \cite{PyPyJIT} and \cite{PyPyJIT09}.

The main difference between the JIT compilers generated by PyPy and the
ones found in other projects like IronPython is that the latter compile
code at the method granularity: they can do little to optimize most of
the operations inside, because few assumptions can be made about the
types of the arguments and the
global state of the program.  The PyPy JITs, on the other hand, work at
a sub-method granularity, as described next.

When using PyPy, the first step is to write an interpreter for the chosen language.  Since it
must be fed to the translation toolchain, the interpreter has to be written in
RPython.  Then, to guide the process, we need to add few manual
annotations (called hints) to the interpreter, in order to teach the JIT generator which
information is important to know at compile-time.  
From these annotations, PyPy will statically generate an interpreter and a JIT
compiler in a single executable (here a .NET executable).

The interesting property of the generated JIT compiler is to delay the
compilation until it knows all the information needed to generate
efficient code.  In other words, at runtime, when the interpreter notice
that it is useful to compile a given piece of code, it sends it to the
JIT compiler; however, if at some point the JIT compiler does not know
about something it needs, it generates a \emph{callback} into itself and stops
execution.

Later, when the generated code is executed, the callback might be hit and the JIT
compiler is restarted again.  At this point, the JIT knows exactly the state
of the program and can exploit all this extra knowledge to generate highly
efficient code.  Finally, the old code is patched and linked to the newly
generated code, so that the next time the JIT compiler will not be invoked
again.  As a result, \textbf{runtime and compile-time are continuously
interleaved}. 

Potentially, the JIT compiler generates new code for each different run-time
value seen in variables it is interested in.
This implies that the generated code needs to contain some sort of updatable
switch, called \emph{flexswitch}, which can pick the right code path based on the
run-time value.  Typically, the value we switch on is the runtime dynamic type
of a value, so that the JIT compiler has all information needed to produce
very good code for that specific case.

Modifying the old code to link to the newly generated one is very challenging on
.NET, as the framework does not offer any primitive to do this.  Section
\ref{sec:clibackend} explains how it is possible to obtain this behaviour.
