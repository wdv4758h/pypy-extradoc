
\documentclass{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage[utf8]{inputenc}

\usepackage{amsmath}


\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{ICOOOLPS workshop 2014}{July 28th, 2014, Uppsala, Sweden}
\copyrightyear{2014}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish,
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers,
                                  % short abstracts)

%% \titlebanner{banner above paper title}        % These are ignored unless
%% \preprintfooter{short description of paper}   % 'preprint' option specified.

\title{The Way Forward in Parallelizing Dynamic Languages}
\subtitle{Position Paper, ICOOOLPS'14}

\authorinfo{Remi Meier}
           {Department of Computer Science\\ ETH ZÃ¼rich}
           {remi.meier@inf.ethz.ch}
\authorinfo{Armin Rigo}
           {www.pypy.org}
           {arigo@tunes.org}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore,
% you may leave them out
%% \terms
%% term1, term2

\keywords
transactional memory, dynamic languages, parallelism, global interpreter lock

\section{Introduction}
In a world where computers get more and more cores and single-thread
performance increases less and less every year, many dynamic languages
have a problem. While there is certainly a lot of popularity around
languages like Python and Ruby, their ability to make use of multiple
cores is somewhat limited. For ease of implementation they chose to
use a single, global interpreter lock (GIL) to synchronize the
execution of code in multiple threads. While this is a
straight-forward way to eliminate synchronization issues in the
interpreter, it prevents parallel execution. Code executed in multiple
threads will be serialized over this GIL so that only one thread can
execute at a time.

There exist several solutions and work-arounds to remove or avoid the
GIL in order to benefit from multiple cores. We are going to discuss
several of them and try to find the best way forward. The first
approach uses fine-grained locking to replace the single GIL. Then
there are shared-nothing models that use for example multiple
processes with multiple interpreters and explicit message
passing. Finally, one can also directly replace the GIL with
transactional memory (TM), either software-based (STM) or
hardware-based (HTM).

The approach that wins in the end should perform similarly for
single-threaded execution as compared to the GIL and be able to
execute code in parallel on multiple cores. Furthermore, we will also
take into account the compatibility to existing code that already uses
threads for concurrency, as well as the changes that are required to
the interpreter itself.

These requirements are not easy to meet. We argue that STM is the
overall winner. While it has a big performance problem currently, it
gets more points in all the other categories. We think that it is the
only solution that also provides a better synchronization mechanism to
the application in the form of atomic blocks.

%% \subsection{Issue}
%% The issue that we want to discuss is how to efficiently support
%% multi-core parallel execution of code in dynamic languages that were
%% designed with GIL semantics in mind.

%% Furthermore, a solution to this problem should also bring better
%% synchronization mechanism with it...

%% (supporting (large) atomic blocks for synchronization)

%% \subsection{Our Position}
%% Current solutions for replacing the GIL include STM, HTM, and
%% fine-grained locking. STM is usually too slow, HTM very limited, and
%% locking suffers from complexity that makes it hard to implement
%% correctly. We argue that the best way forward is still STM and that
%% its performance problem can be solved.

%% Current solutions like STM, HTM, and fine-grained locking are slow, hard
%% to implement correctly, and don't fit the specific problems of dynamic
%% language.  STM is the best way forward but has bad performance, so we
%% fix that.

\section{Discussion}

\paragraph{dynamic language VM problems}

- high allocation rate (short lived objects)\\
- (don't know anything about the program that runs until it actually runs: arbitrary atomic block size)


\subsection{Why is there a GIL?}
The GIL is a very simple synchronization mechanism for supporting
multi-threading in the interpreter. The basic guarantee is that the
GIL may only be released in-between bytecode instructions. The
interpreter can thus rely on complete isolation and atomicity of these
instructions. Additionally, it provides the application with a
sequential consistency model. As a consequence, applications can rely
on certain operations to be atomic and that they will always be
executed in the order in which they appear in the code. While
depending on this may not always be a good idea, it is done in
practice. A solution replacing the GIL should therefore uphold these
guarantees, while preferably also be as easily implementable as a GIL
for the interpreter.
[xxx mention that the interpreter is typically very large and maintained
by open-source communities]

The GIL also allows for easy integration with external C libraries that
do not need to be thread-safe. For the duration of the calls, we
simply do not release the GIL. External libraries that are explicitly
thread-safe can voluntarily release the GIL themselves in order to
still provide some parallelism. This is done for example for
potentially long I/O operations. Consequently, I/O-bound,
multi-threaded applications can actually parallelize to some
degree. Again, a potential solution should be able to integrate with
external libraries with similar ease. We will however focus our
argumentation more on running code in the interpreted language in
parallel, not the external C calls.

Since the GIL is mostly an implementation detail of the interpreter,
it is not exposed to the application running on top of it. To
synchronize memory accesses in applications using threads, the
state-of-the-art still means explicit locking everywhere. It is well
known that using locks for synchronization is not easy.  They are
non-composable, have overhead, may deadlock, limit scalability, and
overall add a lot of complexity. For a better parallel programming
model for dynamic languages, we propose another, well-known
synchronization mechanism called \emph{atomic blocks}.

Atomic blocks are composable, deadlock-free, higher-level and expose
useful atomicity and isolation guarantees to the application for a
series of instructions.  Interpreters using using a GIL can simply
guarantee that the GIL is not released during the execution of the
atomic block. Of course, this still means that no two atomic blocks
can execute in parallel or even concurrently. Potential solutions
that provide a good way to implement atomic blocks are therefore
preferable.



\subsection{Potential Solutions}

For the discussion we define a set of criteria to evaluate the
multiple potential solutions for removing or avoiding the GIL and its
limitations:

\begin{description}
\item[Performance:] How well does the approach perform compared to the
  GIL on single and multiple threads?
\item[Existing applications:] How big are the changes required to
  integrate with and parallelize existing applications?
\item[Better synchronization:] Does the approach enable better
  synchronization mechanisms for applications (e.g. atomic blocks)?
\item[Implementation:] How difficult is it to implement the approach
  in the interpreter?
\item[External libraries:] Does the approach allow for easy
  integration of external libraries?
\end{description}


\subsubsection{Fine-Grained Locking}

The first obvious candidate to replace the GIL is to use multiple
locks instead of a single global lock. By refining the granularity of
the locking approach, we gain the ability to run code that does not
access the same objects in parallel. What we lose instead is the
simplicity of the GIL approach. With every additional lock, the
likeliness of deadlocks grows, as well as the overhead that acquiring
and releasing locks produces.

Jython\footnote{www.jython.org} is one project that implements an
interpreter for Python on the JVM\footnote{Java Virtual Machine} and
that uses fine-grained locking to correctly synchronize the
interpreter. For a language like Python, one needs quite a few,
carefully placed locks. Since there is no central location, the
complexity of the implementation is quite a bit greater compared to
using a GIL. Integrating external, non-thread-safe libraries should
however be very simple too.  One could simply use one lock per library
to avoid this issue.

In the end, fine-grained locking can transparently replace the GIL
and therefore parallelize existing applications without any
changes. It does however not provide a better synchronization
mechanism to the application like e.g. atomic blocks.

%% - support of atomic blocks?\\
%% - hard to get right (deadlocks, performance, lock-granularity)\\
%% - very hard to get right for a large language\\
%% - hard to retro-fit, as all existing code assumes GIL semantics\\
%% - (there are some semantic differences, right? not given perfect lock-placement, but well)
%% ( http://www.jython.org/jythonbook/en/1.0/Concurrency.html )

\subsubsection{Shared-Nothing / multiple processes}

There are also approaches that work around the GIL instead of trying
to replace it. If an application can be split into completely
independent parts that only very rarely need to share anything, or
only do so via an external program like a database, then it is
sensible to have one GIL per independent part. As an example of such
an approach we look at the
\emph{multiprocessing}\footnote{https://docs.python.org/2/library/multiprocessing.html}
module of Python. In essence, it uses process-forking to provide the
application with multiple interpreters that can run in parallel.
Communication is then done explicitly through pipes.

Obviously not every application fits well into this model and its
applicability is therefore quite limited. Performance is good as
long as the application does not need to communicate a lot, because
inter-process communication is relatively expensive. Also the
implementation of this approach is very cheap since one can
actually take an unmodfied GIL-supported interpreter and run
multiple of them in parallel. That way, we also inherit the
easy integration of external libraries without any changes.
While the model of explicit communication is often seen as a
superior way to synchronize concurrent applications because
of its explicitness, it does not actually introduce a better
synchronization mechanism for applications.

%% - often needs major restructuring of programs (explicit data exchange)\\
%% - sometimes communication overhead is too large\\
%% - shared memory is a problem, copies of memory are too expensive


\subsubsection{Transactional Memory}
Transactional memory (TM) can be used as a direct replacement for a
single global lock. Transactions provide the same atomicity and
isolation guarantees as the GIL provides for the execution of bytecode
instructions. So instead of acquiring and releasing the GIL between
these instructions, this approach runs the protected instructions
inside transactions.

TM can be implemented in software (STM) or in hardware (HTM. There are
also some hybrid approaches that combine the two. We count these
hybrid approaches as STM, since they usually provide the same
capabilities as software-only approaches but with different
performance characteristics. We will now first look at HTM that
recently gained a lot of popularity by its introduction in common
desktop CPUs from Intel (Haswell generation).

\paragraph{HTM}

HTM provides us with transactions like any TM system does. It can
be used as a direct replacement for the GIL. However, as is common
with hardware-only solutions, there are quite a few limitations
that can not be lifted easily. For this comparison, we look at
the implementation of Intel in recent Haswell generation CPUs.

HTM in these CPUs works on the level of caches. This has a few
consequences like false-sharing on the cache-line level, and most
importantly it limits the amount of memory that can be accessed within
a transaction. This transaction-length limitation makes it necessary
to have a fallback in place in case this limit is reached. In recent
attempts, the usual fallback is the GIL (XXX: cite). The current
generation of HTM hits this limit very often for our use case (XXX:
cite ruby GIL paper) and therefore does not parallelize that well.

The performance of HTM is pretty good (XXX: cite again...) as it does
not introduce much overhead. And it can transparently parallelize
existing applications to some degree. The implementation is very
straight-forward because it directly replaces the GIL in a central
place. HTM is also directly compatible with any external library that
needs to be integrated and synchronized for use in multiple
threads. The one thing that is missing is support for a better
synchronization mechanism for the application. It is not possible
in general to expose the hardware-transactions to the application
in the form of atomic blocks because that would require much
longer transactions. 

%% - false-sharing on cache-line level\\
%% - limited capacity (caches, undocumented)\\
%% - random aborts (haswell)\\
%% - generally: transaction-length limited (no atomic blocks)

\paragraph{STM}

STM provides all the same benefits as HTM except for its performance.
It is not unusual for the overhead introduced by STM to be between
100\% to even 1000\%. While STM systems often scale very well to a big
number of threads and eventually overtake the single-threaded
execution, they often provide no benefits at all for low numbers of
threads (1-8). There are some attempts (XXX: cite fastlane) that can
reduce the overhead a lot, but also scale very badly so that their
benefit on more than one thread is little.

However, STM compared to HTM does not suffer from the same restricting
limitations. Transactions can be arbitrarily long.  This makes it
possible to actually expose transactions to the application in the
form of atomic blocks. This is the only approach that enables a better
synchronization mechanism than locks for applications \emph{and} still
parallelizes when using it. We think this is a very important point
because it not only gives dynamic languages the ability to parallelize
(already commonplace in most other languages), but also pushes
parallel programming forward. Together with sequential consistency it
provides a lot of simplification for parallel applications.

%% - overhead (100-1000\%) (barrier reference resolution, kills performance on low \#cpu)
%% (FastLane: low overhead, not much gain)\\
%% - unlimited transaction length (easy atomic blocks)

\section{The Way Forward}
possible solution:\\
- use virtual memory paging to somehow lower the STM overhead\\
- tight integration with GC and jit?


%% \appendix
%% \section{Appendix Title}

%% This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}


\end{document}

