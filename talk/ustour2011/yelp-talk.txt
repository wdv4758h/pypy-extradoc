.. include:: <s5defs.txt>

=========================================================
PyPy
=========================================================


.. admonition:: Armin Rigo

    - *Heinrich-Heine Universität, Germany*
    - *Open End AB, Sweden*

    March 2011



Introduction
-----------------------

* The PyPy project (1): a framework in which to write interpreters for
  complicated dynamic languages

* The PyPy project (2): a Python interpreter, supporting the complete
  Python 2.7




CPython and PyPy
--------------------------------------------------------------------


CPython and PyPy
----------------

* Two implementations

* Two interpreters

* CPython is written in C, PyPy is written in Python

* PyPy tries to be equivalent to CPython


...and Jython and IronPython
----------------------------

* Jython: Python for the Java VM

* IronPython: Python for .NET

* Both try to integrate well with their VM


What is PyPy
------------

* A project started in 2003

* An Open Source effort of volunteers

* With some funding support: 2 years from the European Union (2005-2007),
  and now from Germany and Sweden (2010-2011).


What is PyPy
------------

* Test-driven development

* Now contains about 200 KLoC, and 150 KLoc of tests


What is the point of PyPy?
--------------------------

* CPython is older, it's the "official" version

* PyPy is just a replacement, so why?

* Moreover PyPy is not quite complete (e.g. C extension
  modules are only partially supported)


Speed
-----

* First answer: PyPy is faster, and may use less memory

* ...or at least, it is "often" the case


http://speed.pypy.org/
----------------------

.. image:: speed.png


And (optionally) extra features
-------------------------------

* "Stackless"

* Non-Python interpreters

* and many smaller experiments

* it is a better experimentation platform than CPython


Multi-threading
---------------

* Bad support on CPython (GIL)

* PyPy has no answer to this question (there is also a GIL)




PyPy for the user
------------------------------------------------------------------------


Speed
-----

.. image:: speed.png


Speed (2)
---------

.. image:: speed2.png


Memory usage
------------

* Depends on the use case

* Much better than CPython for instances of classes with no __slots__

* On running PyPy's translation toolchain on 32-bits: 1.7GB with PyPy
  (including the JIT machine code), versus 1.2GB with CPython

* Experimental support for 32-bit "compact pointers" on 64-bit platforms


Just-in-Time Compilation
------------------------

* Tracing JIT, like TraceMonkey

* Complete by construction

* Supports Intel x86, amd64, and soon ARM


Compatibility
-------------

* "Full" compatibility with CPython

* More so than, say, Jython or IronPython

* Main difference: Garbage Collection is not refcounting (because we
  could get much better GCs) --- so __del__ methods are not called
  immediately and predictively

* Apart from that, it is really 99.99% compatible


Stackless Python
----------------

* Supports Stackless Python (microthreads)

* In-progress: not integrated with the JIT so far


CPyExt
------

* A layer that integrates existing CPython C extension modules

* Does not support all the details of the CPython C API

* For some extension modules, we can have a performance issue

* Work-in-progress


CPyExt works "often"
--------------------

* wxPython

* PIL

* Boost

* cx_Oracle

* mysqldb

* pycairo


Using CPyExt
------------

* The C sources need recompiling

* Sadly, they often contain a few details to fix

* (typically, bad usage of reference counts)


Other ways to use C libraries
-----------------------------

* Use ctypes (it is soon going to be fast on top of PyPy).
  Example: pyexpat, sqlite3

* Or write it as an RPython module built into PyPy,
  but that's more involved

* More ways could be possible, given work (SWIG backend,
  Cython backend, C++ Reflex, etc...)




Architecture
----------------------------------------------------------------------


Architecture
------------

PyPy has two parts:

* A Python interpreter, written in *RPython*

* A compilation toolchain -- the "translator" -- that translates
  RPython code into C code (mainly)


PyPy's Python interpreter
-------------------------

* A priori similar to CPython, but written in RPython.

* RPython is also valid Python: we test extensively by running
  it on top of CPython


The translation toolchain
-------------------------

* Takes a program written in RPython, a custom subset of Python

* Outputs the "same" program written in C


RPython is still mostly Python
------------------------------

* Completely valid Python (can be tested directly)

* Can use lists, dicts, tuples, classes and instances, and so on,
  but it must be type-safe

* Contains no garbage collection detail (Py_INCREF/Py_DECREF in CPython)

* Really a subset of Python: roughly "how a Java programmer writes his
  first Python program"

* ...well, plus tons of tricks ``:-)``


RPython meta-programming
------------------------

* RPython is actually only a restriction on the code after being imported,
  so we can build up everything in (normal) full Python::

    for name in ["add", "sub", "mul"]:
        def f(x, y):
            ...
        globals()[name] = f

* here, the code in ``f()`` is RPython, but the loop around it is not.


Translation toolchain
---------------------

* "Translation toolchain": statically compiles RPython code

* Produces C code (or JVM or .NET code, experimentally)

* Every aspect that is independent from the high-level
  description of the interpreter is left out of RPython

* Instead, they are added during translation


Translation overview (1)
------------------------

* Start with the live RPython program

* Build the Control Flow Graphs (CFGs) of the functions

* Perform global type inference

* We get a type-annotated version of the CFGs

* Demo


Translation overview (2)
------------------------

* "Lower" the level of the CFGs: transform their Python-like operations
  into C-like operations

* Do a number of additional transformations to insert the selected "aspects"

* Generate C code from the low-level CFGs


Various aspects
---------------

* The object model, e.g. how to turn RPython classes and instances
  to C structs

* Garbage collection

* Execution model: regular (recursive) or stackless

* Just-in-Time compiler




Just-in-Time Compiler
---------------------------------------------------------------------


Goal
----

* Speed up the interpreter written in RPython

* Independent of the language that is being interpreted

* Let us call it the P-interpreter (P = Python or other)


What is a JIT
-------------

* A JIT selects pieces of the user program (in language P) that would benefit
  from compilation instead of interpretation

* A "method JIT" selects individual P functions and compiles them,
  possibly doing some inlining to improve performance (HotSpot, Psyco)

* A "tracing JIT" selects individual code paths from loops and compiles
  them, inlining aggressively (TraceMonkey, PyPy)


Tracing
-------

* Run the user program, and do some lightweight profiling of loops

* When a loop is run often enough, enter "Tracing Mode"

* Run one more iteration of the loop in this mode

* In addition to actually running the next iteration, it records a "trace"


Tracing (2)
-----------

* The trace is then turned into a machine code loop, and directly executed

* Runs all the further iterations of the loop


Tracing (3)
-----------

* The machine code contains "guards" checking that all conditions met
  during tracing are still valid

* When a guard fails (latest: at the end of the loop), we fall back to
  the regular P-interpreter


Meta-Tracing in PyPy
--------------------

* The explanation above assumes a tracing JIT for the full Python
  language

* Would need to be maintained whenever we change the Python version we
  support

* Instead, we have a "meta-tracing JIT"

* We trace the P-interpreter's main loop (running N times) interpreting
  a P loop (running once)


Demo
----


Architecture of the PyPy JIT
----------------------------

* In advance, turn the CFGs of the P-interpreter into some bytecode
  representation called "jitcode"

* Uses some hints provided by the P-interpreter author (but not many)

* "Links" into the P-interpreter's bytecode dispatch loop

* In this way we add lightweight profiling code


Meta-Tracing
------------

* When thresholds are reached, we start tracing

* Tracing is done by running the "jitcodes" in a custom interpreter,
  and recording a trace of all operations performed

* Tracing is slow (double interpretation) but only runs for one iteration
  of the loop


Optimization
------------

* Advanced optimizations of the trace: escaping analysis, integer bounds,
  store sinking, string handling, FFI calls, unrolling, virtualrefs...


Machine Code Backend
--------------------

* Turns a trace into machine code

* Simple register allocation (linear code)

* x86, x86-64, (ARM)

* Guards compiled as conditional jumps to code that restores the full state


Blackhole interpreter
---------------------

* When a guard fails, we need to go back to the regular P-interpreter

* Cannot easily re-enter the P-interpreter from anywhere, because it
  is just C code

* Instead we use one more interpreter, the "blackhole interpreter".


Bridges
-------

* When a guard fails often enough, run again the JIT from there

* Meta-trace, optimize, generate machine code, run it

* Such extra traces are called "bridges" instead of "loops"

* In practice, most loops end up needing some number of bridges

* We get "trees" of machine code


More topics
-----------

* Loops, bridges and "preamble loops"

* Virtualizables

* GC integration

* Memory management of machine code

* ...




Conclusion
---------------------------------------------------------------------


Conclusion
----------

* PyPy is a platform for writing efficient interpreters for
  dynamic languages

* http://pypy.org/

* http://speed.pypy.org/

* irc: ``#pypy at freenode.net``

* noisebridge sprint this weekend (from 10am):
  https://www.noisebridge.net/wiki/Getting_Here
